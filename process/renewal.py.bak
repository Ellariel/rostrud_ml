import wget
import os
import sys
import shutil
import pandas as pd
import hashlib
import rostrud_ml.process.parsing_xmls
from rostrud_ml.utils.config import Config
from rostrud_ml.process.utils import get_date, unzip_cv, get_parser, make_df, to_str_wquotes
from rostrud_ml.process.adding_tables_psycopg import AddingDataPsycopg
from rostrud_ml.process.process import process
from rostrud_ml.process.geti import hashes, update_hashes
from rostrud_ml.process.adding_tables_psycopg_rostrud import *

# в url можно передавать только ссылки с датой (пример: 
# https://opendata.trudvsem.ru/oda2Hialoephidohyie1oR6chaem1oN0quiephooleiWei1aiD/7710538364-cv/data-20220204T044647-structure-20161130T143000.xml.gz)
class Renewal:
    """ Функции класса последовательно скачивают xml файл с ftp, парсят нужные данные, 
    обновляют БД, удаляют временные файлы и папки в бакете"""
    def __init__(self, table_name, url):
        self.name = table_name
        self.pathfrom = url
        # в случаях передачи в класс ссылки без даты (напр. regions.xml) в self.date попадает вся ссылка
        # здесь дата в формате 20180101 (имеет смысл исправить!)
        raw_date = get_date(self.pathfrom)
        self.date = raw_date[:4] + '-' + raw_date[4:6] + '-' + raw_date[6:]
        self.workdir = Config(os.path.join('.', 'rostrud_ml/utils/all_tables_names.yml')).get_config('working_directory')
        self.datadir = os.path.join(self.workdir, table_name)
        if not os.path.isdir(self.datadir):
            os.mkdir(self.datadir)
        self.pathxml = os.path.join(self.datadir, self.date + self.name + '.xml')
    
    def download(self):
        if self.pathfrom.rsplit('.', maxsplit=1)[-1] == 'gz':
            pathgz = self.pathxml + '.gz'#os.path.join(self.datadir, self.pathxml + '.gz')
            print(pathgz)
            wget.download(self.pathfrom, pathgz)
            unzip_cv(pathgz)
        if self.pathfrom.rsplit('.', maxsplit=1)[-1] == 'xml':
            wget.download(self.pathfrom, self.pathxml)
        print('Файлы скачены:', self.date)
            
    def parse_update(self):
        to_delete = ['stat_citizens', 'industries', 'professions', 'regions', 'stat_companies']
        if self.name in to_delete:
            add_data = AddingDataPsycopg()
            add_data.delete_table(self.name, 'project_trudvsem')
            add_data.create_table(self.name, 'project_trudvsem')
            add_data.conn.close()
            parser = get_parser(self.name)
            parser.to_csvs()
            self.df = make_df(self.datadir)
            self.df = process(self.name, self.df)
            #открывается соединение с БД
            add_data = AddingDataPsycopg()
            add_data.write_to_sql(self.df, self.name, 'project_trudvsem')
            print(self.name + ": добавлено: ", self.df.shape[0], ' строк')
            add_data.conn.close()
            
        elif self.name == 'cvs':
            parser = get_parser(self.name, self.pathxml)
            for table in ['curricula_vitae', 'workexp', 'edu', 'addedu']: #
                self.df = parser.to_csvs(table)
                self.df = process(table, self.df)
                print(table, ": обработано")
                #открывается соединение с БД
                add_data = AddingDataPsycopg()
                # записываем в БД
                add_data.write_to_sql(self.df, table, 'project_trudvsem')
                print(table + ": добавлено: ", self.df.shape[0], ' строк')
         
                add_data.conn.close()
                    
        elif self.name == 'vacancies':
            parser = get_parser(self.name)
            parser.to_csvs()
            print(self.date)
            #открывается соединение с БД
            add_data = AddingDataPsycopg()
            old_hash_set = add_data.get_table_as_df('md5_hash, inactive', 'vacancies', 'project_trudvsem')
            old_hash_list = old_hash_set['md5_hash'].tolist()
            self.df = make_df(self.datadir)
            variables_list = Config(os.path.join('.', 'rostrud_ml/utils/all_tables_names.yml')).get_config('md5_hash')
            variables = variables_list['vacancies']
            self.df['md5_hash'] = self.df[variables].apply(lambda row: hashlib.md5(','.join(row.values.astype(str)).encode()).hexdigest(), axis=1)
            #при необходимости можно использовать версионирование
            #new_hash_list = self.df['md5_hash'].tolist()
            self.df = self.df.loc[~self.df.md5_hash.isin(old_hash_list), :]
            #active_hash_list = old_hash_set['md5_hash'][old_hash_set['inactive'] == 0].tolist()
            #inactive_hash_list = old_hash_set['md5_hash'][old_hash_set['inactive'] == 1].tolist()
            #inactive = set(active_hash_list).difference(set(new_hash_list))
            #same = set(inactive_hash_list).intersection(set(new_hash_list))
            #print('Проставить флаг неактивности: ', len(inactive))
            #print('Проверить стали ли неактивные активными: ', len(same))
            self.df = process('vacancies', self.df)
            add_data.write_to_sql(self.df, self.name, 'project_trudvsem')
            print(self.name + ": добавлено: ", self.df.shape[0], ' строк')
            # обновим флаги inactive
            #if len(inactive) > 0:
            #    update_inactivation_new('project_trudvsem', 'vacancies', self.date, to_str_wquotes(inactive))
            #if len(same) > 0: 
            #    fix_error_inactivation_new('project_trudvsem', 'vacancies', to_str_wquotes(same))
            add_data.conn.close()
            
        else:
            parser = get_parser(self.name)
            parser.to_csvs()
            self.df = make_df(self.datadir)
            self.df = process(self.name, self.df)
            #открывается соединение с БД
            add_data = AddingDataPsycopg()
            add_data.write_to_sql(self.df, self.name, 'project_trudvsem')
            print(self.name + ": добавлено: ", self.df.shape[0], ' строк')
            add_data.conn.close()
    
    # удаление директории со всем содержимым       
    def delete(self, to_remove=None):
        if to_remove == 'files':
            os.remove(self.pathxml)
            pathgz = self.pathxml + '.gz'
            if os.path.exists(pathgz) and os.path.getsize(pathgz) > 0:
                os.remove(pathgz)
        
        else: 
            shutil.rmtree(self.datadir)
        print("Files deleted")
